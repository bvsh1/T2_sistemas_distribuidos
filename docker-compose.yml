services:
  kafka:
    image: redpandadata/redpanda:v24.1.3
    command: [
      "redpanda", "start",
      "--overprovisioned", "--smp", "1",
      "--reserve-memory", "0M",
      "--node-id", "0",
      "--kafka-addr", "PLAINTEXT://0.0.0.0:9092",
      "--advertise-kafka-addr", "PLAINTEXT://kafka:9092"
    ]
    ports: ["9092:9092"]

  flink-jobmanager:
    build:
      context: ./flink_job
    user: flink # Ejecuta como flink
    volumes:
      - ./flink_job:/opt/flink/job
    command: |
      bash -c "
      /docker-entrypoint.sh jobmanager &
      JOBMANAGER_PID=$$!
      echo 'Esperando 10s para que el cluster inicie...';
      sleep 30;
      echo 'Enviando trabajo de Flink (app.py)...';
      # --- Ya no se necesita PYTHONPATH ---
      flink run -py /opt/flink/job/app.py;
      wait $$JOBMANAGER_PID
      "
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - BOOTSTRAP_SERVERS=kafka:9092
      - SCORE_THRESHOLD=0.62
      - TOPIC_INPUT=questions.answers
      - TOPIC_OUTPUT_VALIDATED=questions.validated
      - TOPIC_OUTPUT_REGENERATE=questions.llm
      # Eliminamos FLINK_PROPERTIES si limpiaste el Dockerfile (copiando el JAR a lib)
    ports: ["8081:8081"]
    depends_on:
    - kafka
    - llm

  flink-taskmanager:
    build:
      context: ./flink_job
    user: flink # Ejecuta como flink
    volumes:
      - ./flink_job:/opt/flink/job
    command: taskmanager # TaskManager recogerá el PYTHONPATH automáticamente
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      # Eliminamos FLINK_PROPERTIES si limpiaste el Dockerfile
    depends_on: [flink-jobmanager]

  generator:
    build: ./generator
    environment:
      - STORAGE_SERVICE_URL=http://bdd:8000
    depends_on:
      - bdd
    restart: on-failure

  llm:
    build: ./llm
    ports:
      - "8003:8003"
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - BOOTSTRAP_SERVERS=kafka:9092
      - TOPIC_REQUESTS=questions.llm
    depends_on:
      - kafka

  retry-overload:
    build: ./retry
    command: python retry_overload.py
    environment:
    - BOOTSTRAP_SERVERS=kafka:9092
    depends_on: [kafka]

  retry-quota:
    build: ./retry
    command: python retry_quota.py
    environment:
    - BOOTSTRAP_SERVERS=kafka:9092
    depends_on: [kafka]

  bdd:
    build: ./bdd
    environment:
    - BOOTSTRAP_SERVERS=kafka:9092
    - DB_URL=sqlite:///data/data.db
    volumes:
      - storage_data:/app/data
    ports:
      - "8001:8000"
    depends_on: [kafka]

  kafdrop:
    image: obsidiandynamics/kafdrop:4.1.0
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      #JVM_OPTS: "-Xms32M -Xmx256M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - kafka

volumes:
  storage_data: {}